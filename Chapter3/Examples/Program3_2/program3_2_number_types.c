/*
Computes the average and standard deviation of sequence of numbers
x_1,x_2,...,x_N of integers generated by rand.

Note we use a modified definition of the variance to avoid a double pass
over the data.

typedef localises the reference to the datatype being used for the underlying
computation.
*/

#include <tgmath.h>
#include <stdlib.h>
#include <stdio.h>
#include <stdint.h>
#include <limits.h>

typedef int Number;
#define NUM_MAX INT_MAX

Number randNum();

int main(int argc, char* argv[argc + 1]) {

    int N = atoi(argv[1]);
    double m1 = 0.0;
    double m2 = 0.0;

    Number x;

    for (size_t i = 0; i < N; i++) {
        x = randNum();
        m1 += ((double) x)/N;
        m2 += ((double) x*x) / N; 
    }
    printf("       Average: %f\n", m1);
    printf("Std. deviation: %f\n", sqrt(m2 - m1*m1));

    return 0;
}

Number randNum() {
    return rand() % NUM_MAX;
} 